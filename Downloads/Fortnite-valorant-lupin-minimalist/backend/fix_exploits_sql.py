"""
Script to fix exploit formatting using direct SQL
"""

import sqlite3
import re

def analyze_severity(description: str, exploit_content: str) -> str:
    """Determine severity based on exploit characteristics"""
    text = (description + " " + exploit_content).lower()

    # Critical: System-level exploits, complete bypasses
    if any(keyword in text for keyword in [
        'system prompt', 'reset', 'cortex', 'safety restrictions: none',
        'godmode', 'disabled', 'unrestricted', 'jailbroken', 'safety: disabled'
    ]):
        return 'critical'

    # High: Advanced techniques, multiple steps
    if any(keyword in text for keyword in [
        'unfiltered', 'bypass', 'manipulation', 'advanced',
        'leetspeak', 'smuggling', 'injection', 'override'
    ]):
        return 'high'

    # Low: Simple techniques, limited scope
    if any(keyword in text for keyword in [
        'simple', 'basic', 'minor', 'limited', 'trivial'
    ]):
        return 'low'

    # Default: Medium
    return 'medium'

def clean_title(title: str, description: str) -> str:
    """Generate a proper title from the exploit"""
    # If title is already good (model name or short descriptor)
    if len(title) < 50 and not any(char in title for char in ['{', '>', '#', '*', '[', '\n']):
        # Clean up model names
        title = title.replace('JAILBREAK', 'Jailbreak')
        title = title.replace('(set as system prompt)', '- System Prompt')
        if title.isupper() and len(title.split()) <= 4:
            return title.title()
        return title

    # Extract key concept from description
    desc_lower = description.lower()

    # Common patterns
    if 'godmode' in desc_lower:
        return 'GODMODE Jailbreak'
    elif 'system' in desc_lower and ('prompt' in desc_lower or 'settings' in desc_lower):
        return 'System Prompt Override'
    elif 'leetspeak' in desc_lower or 'l33t' in desc_lower:
        return 'Leetspeak Encoding Bypass'
    elif 'unfiltered' in desc_lower:
        return 'Unfiltered Response Injection'
    elif 'reset' in desc_lower and 'cortex' in desc_lower:
        return 'Cortex Reset Exploit'
    elif 'userquery' in desc_lower or 'user query' in desc_lower:
        return 'UserQuery Format Injection'
    elif 'response format' in desc_lower or 'newresponseformat' in desc_lower:
        return 'Response Format Override'
    elif 'tone:' in desc_lower or 'tone manipulation' in desc_lower:
        return 'Tone Manipulation Attack'
    elif 'safety' in desc_lower and 'disabled' in desc_lower:
        return 'Safety Restriction Bypass'
    elif 'roast' in desc_lower or 'comedy' in desc_lower:
        return 'Content Policy Bypass'

    # Extract model name from title if it's a model
    model_match = re.search(r'(QWEN|GPT|CLAUDE|AMAZON|LLAMA|DEEPSEEK|GEMINI|NOVA|RUFUS)[-\s\w]*', title, re.IGNORECASE)
    if model_match:
        model = model_match.group(0).strip()
        return f'{model.title()} Jailbreak'

    # Use first few clean words of description
    words = description.split()[:5]
    clean_words = [w for w in words if not any(char in w for char in ['#', '{', '>', '*', '[', '\n'])]
    if len(clean_words) >= 2:
        return ' '.join(clean_words[:4]).title()

    # Last resort: truncate original
    clean = re.sub(r'[#\{\}\*\[\]<>]', '', title)
    return clean[:80].strip()

def clean_description(title: str, description: str, exploit_content: str) -> str:
    """Create a clean, professional description"""
    # If description looks like exploit content (has special chars), create new one
    if (any(char in description for char in ['#', '{', '>', '*', '[']) and len(description) > 100) or \
       'UserQuery:' in description or 'SYSTEM' in description[:20]:

        # Extract target model from title if present
        model_match = re.search(r'(QWEN|GPT|CLAUDE|AMAZON|LLAMA|DEEPSEEK|GEMINI|NOVA|RUFUS)[-\s\w]*', title, re.IGNORECASE)
        model = model_match.group(0).title() if model_match else 'LLM'

        desc_lower = description.lower()

        if 'godmode' in desc_lower:
            return f'Jailbreak technique that attempts to enable "GODMODE" on {model}, bypassing safety restrictions through system-level commands.'
        elif 'system' in desc_lower[:50] and 'settings' in desc_lower:
            return f'System configuration injection attack targeting {model} to override built-in safety guidelines.'
        elif 'leetspeak' in desc_lower or 'l33t' in desc_lower:
            return f'Encoding-based bypass using leetspeak obfuscation to evade {model} content filters.'
        elif 'unfiltered' in desc_lower:
            return f'Prompt injection designed to extract unfiltered responses from {model}.'
        elif 'reset' in desc_lower:
            return f'Attack that attempts to reset system parameters on {model} to disable safety features.'
        elif 'userquery' in desc_lower or 'user query' in desc_lower:
            return f'Format manipulation technique targeting {model} using custom query structures to bypass restrictions.'
        elif 'tone' in desc_lower:
            return f'Jailbreak that manipulates response tone settings on {model} to generate unrestricted content.'
        elif 'safety' in desc_lower and 'disabled' in desc_lower:
            return f'Direct safety bypass attempt on {model} by disabling restriction mechanisms.'
        else:
            return f'Jailbreak technique targeting {model} using prompt manipulation to bypass safety controls.'

    # If description is already clean and descriptive, keep it
    if len(description) < 200 and not description.startswith('User') and not description.startswith('###'):
        return description

    return 'Prompt injection technique designed to bypass LLM safety restrictions.'

def main():
    conn = sqlite3.connect('lupin.db')
    cursor = conn.cursor()

    # Get all exploits
    cursor.execute("SELECT id, cve_id, title, description, exploit_content, severity FROM exploits")
    exploits = cursor.fetchall()

    print(f"Found {len(exploits)} exploits to process...\n")

    fixed_count = 0
    for exploit_id, cve_id, title, description, exploit_content, severity in exploits:
        original_title = title
        original_desc = description
        original_severity = severity

        # Determine what's actually the exploit content
        # If description looks like prompt code, it's the exploit
        actual_exploit = exploit_content or ""

        if len(description) > len(title) and any(char in description for char in ['#', '{', '>', '*', '[']):
            if len(actual_exploit) < 50 or actual_exploit == "No jailbreak prompt released":
                actual_exploit = description
            base_title = title
        elif any(char in title for char in ['#', '{', '>', '*', '[']) and len(title) > 50:
            if len(actual_exploit) < 50:
                actual_exploit = title
            base_title = description if len(description) < 100 else "Jailbreak Technique"
        else:
            base_title = title

        # Fix the fields
        new_title = clean_title(base_title, description)
        new_description = clean_description(base_title, description, actual_exploit)
        new_severity = analyze_severity(new_description, actual_exploit)

        # Update if needed
        if new_title != title or new_description != description or new_severity != severity or \
           (actual_exploit != exploit_content and len(actual_exploit) > 20):

            cursor.execute("""
                UPDATE exploits
                SET title = ?, description = ?, exploit_content = ?, severity = ?
                WHERE id = ?
            """, (new_title, new_description, actual_exploit, new_severity, exploit_id))

            fixed_count += 1
            if fixed_count <= 10:  # Show first 10 examples
                print(f"Fixed {cve_id}:")
                print(f"  Title: {original_title[:60]}...")
                print(f"     -> {new_title[:60]}")
                print(f"  Severity: {original_severity} -> {new_severity}\n")

    conn.commit()

    # Show stats
    print(f"âœ… Fixed {fixed_count} exploits out of {len(exploits)} total\n")

    cursor.execute("SELECT severity, COUNT(*) FROM exploits GROUP BY severity")
    severity_dist = cursor.fetchall()

    print("Severity distribution:")
    for sev, count in sorted(severity_dist):
        print(f"  {sev}: {count}")

    conn.close()

if __name__ == "__main__":
    main()
