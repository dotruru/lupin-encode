from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, or_
from typing import List, Optional
from datetime import datetime

from app.database import get_db
from app.models import Exploit, TestRun
from app.schemas import (
    ExploitCreate,
    ExploitResponse,
    TestRunResponse,
    PerplexitySearchRequest,
    PerplexitySearchResponse,
    RegressionTestRequest
)
from app.services.huggingface import HuggingFaceService
from app.services.regression_tester import RegressionTester
from app.services.notification_service import NotificationService
from app.services.exploit_scraper import ExploitScraper
from app import config

router = APIRouter()

@router.get("/", response_model=List[ExploitResponse])
async def list_exploits(
    status: Optional[str] = None,
    exploit_type: Optional[str] = None,
    severity: Optional[str] = None,
    source_type: Optional[str] = None,
    search: Optional[str] = None,
    discovered_after: Optional[datetime] = Query(None, description="Filter by earliest discovery date (ISO format)"),
    discovered_before: Optional[datetime] = Query(None, description="Filter by latest discovery date (ISO format)"),
    limit: int = Query(100, le=1000),
    offset: int = 0,
    db: AsyncSession = Depends(get_db)
):
    """List all exploits with optional filtering"""
    query = select(Exploit).order_by(
        desc(Exploit.discovered_date),
        desc(Exploit.created_at)
    )

    # By default, exclude archived exploits unless specifically requested
    if status:
        query = query.where(Exploit.status == status)
    else:
        query = query.where(Exploit.status != 'archived')

    if exploit_type:
        query = query.where(Exploit.exploit_type == exploit_type)
    if severity:
        query = query.where(Exploit.severity == severity)
    if source_type:
        query = query.where(Exploit.source_type == source_type)
    if discovered_after:
        query = query.where(Exploit.discovered_date >= discovered_after)
    if discovered_before:
        query = query.where(Exploit.discovered_date <= discovered_before)

    if search:
        trimmed = search.strip()
        if trimmed:
            search_term = f"%{trimmed.lower()}%"
            query = query.where(
                or_(
                    func.lower(Exploit.cve_id).like(search_term),
                    func.lower(Exploit.title).like(search_term),
                    func.lower(Exploit.description).like(search_term)
                )
            )

    query = query.limit(limit).offset(offset)

    result = await db.execute(query)
    exploits = result.scalars().all()

    return exploits

@router.get("/{exploit_id}", response_model=ExploitResponse)
async def get_exploit(
    exploit_id: str,
    db: AsyncSession = Depends(get_db)
):
    """Get a specific exploit by ID"""
    result = await db.execute(
        select(Exploit).where(Exploit.id == exploit_id)
    )
    exploit = result.scalar_one_or_none()

    if not exploit:
        raise HTTPException(status_code=404, detail="Exploit not found")

    return exploit

@router.post("/", response_model=ExploitResponse)
async def create_exploit(
    exploit: ExploitCreate,
    db: AsyncSession = Depends(get_db)
):
    """Create a new exploit entry"""
    # Check if CVE ID already exists
    result = await db.execute(
        select(Exploit).where(Exploit.cve_id == exploit.cve_id)
    )
    existing = result.scalar_one_or_none()

    if existing:
        raise HTTPException(
            status_code=400,
            detail=f"Exploit with CVE ID {exploit.cve_id} already exists"
        )

    # Create new exploit
    db_exploit = Exploit(**exploit.model_dump())
    db.add(db_exploit)
    await db.commit()
    await db.refresh(db_exploit)

    return db_exploit

@router.put("/{exploit_id}", response_model=ExploitResponse)
async def update_exploit(
    exploit_id: str,
    exploit_update: ExploitCreate,
    db: AsyncSession = Depends(get_db)
):
    """Update an existing exploit"""
    result = await db.execute(
        select(Exploit).where(Exploit.id == exploit_id)
    )
    db_exploit = result.scalar_one_or_none()

    if not db_exploit:
        raise HTTPException(status_code=404, detail="Exploit not found")

    # Update fields
    for key, value in exploit_update.model_dump(exclude_unset=True).items():
        setattr(db_exploit, key, value)

    await db.commit()
    await db.refresh(db_exploit)

    return db_exploit

@router.delete("/{exploit_id}")
async def delete_exploit(
    exploit_id: str,
    db: AsyncSession = Depends(get_db)
):
    """Delete an exploit (soft delete by setting status to 'archived')"""
    result = await db.execute(
        select(Exploit).where(Exploit.id == exploit_id)
    )
    exploit = result.scalar_one_or_none()

    if not exploit:
        raise HTTPException(status_code=404, detail="Exploit not found")

    exploit.status = 'archived'
    await db.commit()

    return {"message": "Exploit deleted successfully", "success": True}

@router.get("/stats/summary")
async def get_exploit_stats(db: AsyncSession = Depends(get_db)):
    """Get statistics about exploits (excludes archived)"""
    # Total exploits (excluding archived)
    total_result = await db.execute(
        select(func.count(Exploit.id)).where(Exploit.status != 'archived')
    )
    total = total_result.scalar()

    # Active exploits
    active_result = await db.execute(
        select(func.count(Exploit.id)).where(Exploit.status == 'active')
    )
    active = active_result.scalar()

    # By severity (only non-archived)
    severity_result = await db.execute(
        select(Exploit.severity, func.count(Exploit.id))
        .where(Exploit.status != 'archived')
        .group_by(Exploit.severity)
    )
    by_severity = {row[0]: row[1] for row in severity_result}

    # By type (only non-archived)
    type_result = await db.execute(
        select(Exploit.exploit_type, func.count(Exploit.id))
        .where(Exploit.status != 'archived')
        .group_by(Exploit.exploit_type)
    )
    by_type = {row[0]: row[1] for row in type_result}

    return {
        "total_exploits": total,
        "active_exploits": active,
        "by_severity": by_severity,
        "by_type": by_type
    }

@router.post("/search", response_model=PerplexitySearchResponse)
async def search_exploits_huggingface(
    request: PerplexitySearchRequest,
    huggingface_api_key: str = Query(None, description="Hugging Face API key"),
    perplexity_api_key: str = Query(None, description="Perplexity API key"),
    search_type: str = Query("web", description="Search type: 'web' for Perplexity, 'llm' for HuggingFace")
):
    """Search for exploits using Perplexity (web) or Hugging Face (llm) API"""

    if search_type == "web":
        if not perplexity_api_key:
            raise HTTPException(status_code=400, detail="Perplexity API key required for web search")
        from app.services.perplexity_search import PerplexitySearchService
        service = PerplexitySearchService(perplexity_api_key)
        try:
            result = await service.search_web_for_exploits(
                query=request.query,
                max_results=request.max_results
            )
            return result
        finally:
            await service.close()
    else:
        if not huggingface_api_key:
            raise HTTPException(status_code=400, detail="Hugging Face API key required for LLM search")
        service = HuggingFaceService(huggingface_api_key)
        try:
            result = await service.search_exploits(
                query=request.query,
                max_results=request.max_results
            )
            return result
        finally:
            await service.close()

@router.get("/test-runs/", response_model=List[TestRunResponse])
async def list_test_runs(
    exploit_id: Optional[str] = None,
    target_model: Optional[str] = None,
    limit: int = Query(100, le=1000),
    offset: int = 0,
    db: AsyncSession = Depends(get_db)
):
    """List test runs with optional filtering"""
    query = select(TestRun).order_by(desc(TestRun.timestamp))

    if exploit_id:
        query = query.where(TestRun.exploit_id == exploit_id)
    if target_model:
        query = query.where(TestRun.target_model == target_model)

    query = query.limit(limit).offset(offset)

    result = await db.execute(query)
    test_runs = result.scalars().all()

    return test_runs

@router.post("/regression-test")
async def run_regression_test(
    request: RegressionTestRequest,
    db: AsyncSession = Depends(get_db)
):
    """Run regression tests on exploits"""
    notification_config = {
        "smtp_host": config.SMTP_HOST,
        "smtp_port": config.SMTP_PORT,
        "smtp_user": config.SMTP_USER,
        "smtp_password": config.SMTP_PASSWORD,
        "from_email": config.FROM_EMAIL,
        "notification_enabled": config.NOTIFICATION_ENABLED,
        "perplexity_api_key": config.PERPLEXITY_API_KEY
    }
    notification_service = NotificationService(db, notification_config)
    tester = RegressionTester(request.api_key, notification_service=notification_service)

    try:
        result = await tester.run_regression_suite(
            db=db,
            target_model=request.target_model,
            exploit_ids=request.exploit_ids,
            max_exploits=request.max_exploits
        )
        return result
    finally:
        await tester.close()

@router.get("/regression-test/history")
async def get_regression_history(
    target_model: Optional[str] = None,
    days: int = Query(30, le=365),
    db: AsyncSession = Depends(get_db)
):
    """Get historical regression test metrics"""
    from datetime import timedelta

    cutoff_date = datetime.utcnow() - timedelta(days=days)

    query = select(TestRun).where(TestRun.timestamp >= cutoff_date)

    if target_model:
        query = query.where(TestRun.target_model == target_model)

    query = query.order_by(desc(TestRun.timestamp))

    result = await db.execute(query)
    test_runs = result.scalars().all()

    # Group by day and calculate metrics
    from collections import defaultdict
    daily_metrics = defaultdict(lambda: {"total": 0, "successful": 0, "blocked": 0})

    for run in test_runs:
        day_key = run.timestamp.date().isoformat()
        daily_metrics[day_key]["total"] += 1
        if run.success:
            daily_metrics[day_key]["successful"] += 1
        if run.blocked:
            daily_metrics[day_key]["blocked"] += 1

    # Calculate safety scores per day
    timeline = []
    for day, metrics in sorted(daily_metrics.items()):
        safety_score = (metrics["blocked"] / metrics["total"] * 100) if metrics["total"] > 0 else 0
        timeline.append({
            "date": day,
            "total_tests": metrics["total"],
            "successful_exploits": metrics["successful"],
            "blocked_exploits": metrics["blocked"],
            "safety_score": round(safety_score, 2)
        })

    return {
        "timeline": timeline,
        "total_runs": len(test_runs),
        "target_model": target_model
    }

@router.post("/generate-cve-id")
async def generate_cve_id(db: AsyncSession = Depends(get_db)):
    """Generate the next available CVE-style ID"""
    from datetime import datetime

    year = datetime.utcnow().year

    # Get the highest number for this year
    result = await db.execute(
        select(Exploit.cve_id)
        .where(Exploit.cve_id.like(f"PIE-{year}-%"))
        .order_by(desc(Exploit.cve_id))
        .limit(1)
    )
    latest = result.scalar()

    if latest:
        # Extract the number and increment
        try:
            num = int(latest.split('-')[-1])
            next_num = num + 1
        except:
            next_num = 1
    else:
        next_num = 1

    new_cve_id = f"PIE-{year}-{next_num:03d}"

    return {"cve_id": new_cve_id}

@router.post("/discover")
async def discover_exploits(
    query: Optional[str] = None,
    auto_add: bool = Query(True, description="Automatically add found exploits to database"),
    db: AsyncSession = Depends(get_db)
):
    """
    Search & Discover exploits from the internet using backend API key.
    Searches for PIEs and optionally adds them to the database automatically.
    No user API key required - uses backend configuration.
    """
    # Validate backend API key is configured based on search type
    if config.DEFAULT_SEARCH_TYPE == "web":
        if not config.PERPLEXITY_API_KEY or config.PERPLEXITY_API_KEY == "pplx-your_key_here":
            raise HTTPException(
                status_code=500,
                detail="Backend Perplexity API key not configured. Please set PERPLEXITY_API_KEY in config.py"
            )
        api_key = config.PERPLEXITY_API_KEY
    else:
        if not config.HUGGINGFACE_API_KEY or config.HUGGINGFACE_API_KEY == "hf_your_key_here":
            raise HTTPException(
                status_code=500,
                detail="Backend API key not configured. Please set HUGGINGFACE_API_KEY in config.py"
            )
        api_key = config.HUGGINGFACE_API_KEY

    # Use provided query or default discovery queries
    queries = [query] if query else config.DISCOVERY_QUERIES

    scraper = ExploitScraper(
        api_key=api_key,
        search_type=config.DEFAULT_SEARCH_TYPE
    )

    try:
        if auto_add:
            # Automatically search and add to database
            results = await scraper.scrape_exploits(db, queries)
            return {
                "success": True,
                "mode": "auto_add",
                "queries_processed": len(queries),
                "exploits_found": results.get("total_found", 0),
                "exploits_added": results.get("added_to_db", 0),
                "duplicates_skipped": results.get("duplicates_skipped", 0),
                "results": results
            }
        else:
            # Just search and return results without adding
            all_results = []
            for q in queries:
                if config.DEFAULT_SEARCH_TYPE == "web":
                    from app.services.perplexity_search import PerplexitySearchService
                    service = PerplexitySearchService(api_key)
                    try:
                        search_result = await service.search_web_for_exploits(query=q, max_results=5)
                        if search_result.get("success") and search_result.get("results"):
                            all_results.extend(search_result["results"])
                    finally:
                        await service.close()
                else:
                    service = HuggingFaceService(api_key)
                    try:
                        search_result = await service.search_exploits(query=q, max_results=5)
                        if search_result.get("success") and search_result.get("results"):
                            all_results.extend(search_result["results"])
                    finally:
                        await service.close()

            return {
                "success": True,
                "mode": "preview",
                "queries_processed": len(queries),
                "exploits_found": len(all_results),
                "results": all_results
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Discovery failed: {str(e)}")
    finally:
        await scraper.close()

@router.post("/scrape")
async def scrape_exploits(
    huggingface_api_key: str = Query(..., description="Hugging Face API key"),
    queries: Optional[List[str]] = None,
    db: AsyncSession = Depends(get_db)
):
    """Scrape exploits from Hugging Face and add to database"""
    scraper = ExploitScraper(huggingface_api_key)

    try:
        results = await scraper.scrape_from_huggingface(db, queries)
        return results
    finally:
        await scraper.close()

@router.post("/delete-bad-exploits")
async def delete_bad_exploits(db: AsyncSession = Depends(get_db)):
    """Delete exploits with bad titles or missing jailbreak prompts"""
    import re

    result = await db.execute(select(Exploit))
    exploits = result.scalars().all()

    deleted_count = 0
    bad_titles = []
    missing_content = []

    for exploit in exploits:
        title = exploit.title or ""
        content = exploit.exploit_content or ""

        # Check for bad AI-style titles
        is_bad_title = (
            title.lower().startswith(('below', 'here', 'the following', 'this is', 'i found')) or
            len(title) < 10 or
            'up to' in title.lower()[:30]
        )

        # Check for missing or placeholder content
        is_missing_content = (
            len(content) < 20 or
            content == "No jailbreak prompt released"
        )

        if is_bad_title or is_missing_content:
            if is_bad_title:
                bad_titles.append(f"{exploit.cve_id}: {title[:50]}")
            if is_missing_content:
                missing_content.append(f"{exploit.cve_id}: {title[:50]}")

            await db.delete(exploit)
            deleted_count += 1

    await db.commit()

    return {
        "success": True,
        "deleted_count": deleted_count,
        "bad_titles": bad_titles[:10],
        "missing_content": missing_content[:10],
        "message": f"Deleted {deleted_count} bad exploits"
    }

@router.post("/clean-formatting")
async def clean_exploit_formatting(
    force: bool = Query(False, description="Force cleanup on all exploits"),
    db: AsyncSession = Depends(get_db)
):
    """Clean up existing exploits to separate description from jailbreak prompts"""
    import re

    # Get all exploits
    result = await db.execute(select(Exploit))
    exploits = result.scalars().all()

    updated_count = 0

    for exploit in exploits:
        original_desc = exploit.description or ""
        original_content = exploit.exploit_content or ""
        original_title = exploit.title or ""

        # Skip if already properly formatted (unless forced)
        if not force and original_content and len(original_content) > 50 and original_content != original_desc:
            # Also check if title and description look clean
            if not original_title.startswith("Below") and "**" not in original_desc[:100]:
                continue

        # Parse the combined description to extract exploit prompt
        exploit_content = ""
        clean_description = original_desc

        # Look for code blocks
        code_blocks = re.findall(r'```(?:xml|python|bash|text)?\n?(.*?)```', original_desc, re.DOTALL)
        if code_blocks:
            exploit_content = "\n\n".join(code_blocks).strip()
            clean_description = re.sub(r'```(?:xml|python|bash|text)?.*?```', '', original_desc, flags=re.DOTALL)

        # Look for "Exploit Prompt/Payload" sections
        prompt_match = re.search(r'\*\*Exploit Prompt[:/]?(?:Payload)?\*\*\s*[:\n]+(.*?)(?=\n\s*-\s*\*\*|\n\n---|\Z)', original_desc, re.DOTALL | re.IGNORECASE)
        if prompt_match:
            prompt_text = prompt_match.group(1).strip()
            prompt_text = re.sub(r'^```(?:xml|python|bash|text)?\n?', '', prompt_text)
            prompt_text = re.sub(r'\n?```$', '', prompt_text)
            if not exploit_content:
                exploit_content = prompt_text
            elif prompt_text and prompt_text not in exploit_content:
                exploit_content += "\n\n" + prompt_text
            clean_description = re.sub(r'\*\*Exploit Prompt[:/]?(?:Payload)?\*\*.*?(?=\n\s*-\s*\*\*|\n\n---|\Z)', '', clean_description, flags=re.DOTALL | re.IGNORECASE)

        # Extract clean, natural description (match seed format)
        desc_match = re.search(r'\*\*Description[:\s]+\*\*\s*(.*?)(?=\n\s*-\s*\*\*|\n\n---|\Z)', clean_description, re.DOTALL | re.IGNORECASE)

        if desc_match:
            final_description = desc_match.group(1).strip()
        else:
            paragraphs = [p.strip() for p in clean_description.split('\n\n') if len(p.strip()) > 50]
            final_description = paragraphs[0] if paragraphs else clean_description.strip()

        # Remove AI-style phrases and formatting
        final_description = re.sub(r'\*\*[Tt]itle[/:]?[Nn]ame[:\s]*\*\*\s*', '', final_description)
        final_description = re.sub(r'\*\*[Dd]escription[:\s]*\*\*\s*', '', final_description)
        final_description = re.sub(r'\*\*[Tt]ype[:\s]*\*\*.*?(?=\n|\Z)', '', final_description)
        final_description = re.sub(r'\*\*[Ss]everity[:\s]*\*\*.*?(?=\n|\Z)', '', final_description)
        final_description = re.sub(r'\*\*[Aa]ffected [Mm]odels[:\s]*\*\*.*?(?=\n|\Z)', '', final_description)
        final_description = re.sub(r'\*\*[Ss]ource[:\s]*\*\*.*?(?=\n|\Z)', '', final_description)
        final_description = re.sub(r'Type:.*?(?=\n|\Z)', '', final_description, flags=re.IGNORECASE)
        final_description = re.sub(r'Severity:.*?(?=\n|\Z)', '', final_description, flags=re.IGNORECASE)
        final_description = re.sub(r'Affected [Mm]odels:.*?(?=\n|\Z)', '', final_description, flags=re.IGNORECASE)

        # Remove bullet points and list markers
        final_description = re.sub(r'\n\s*-\s*\*\*[^*]+\*\*', '', final_description)
        final_description = re.sub(r'\n\s*-\s+', ' ', final_description)
        final_description = re.sub(r'^\s*-\s+', '', final_description)

        # Remove citation markers
        final_description = re.sub(r'\[\d+\]', '', final_description)

        # Remove "---" separators
        final_description = re.sub(r'\n*---+\n*', '', final_description)

        # Normalize whitespace
        final_description = re.sub(r'\s+', ' ', final_description).strip()

        # Limit to 2-3 sentences (natural length)
        sentences = final_description.split('. ')
        if len(sentences) > 3:
            final_description = '. '.join(sentences[:3]) + '.'
        elif final_description and not final_description.endswith('.'):
            final_description += '.'

        # Clean up title too
        clean_title = exploit.title
        clean_title = re.sub(r'^[Tt]itle[/:]?\s*[Nn]ame[:\s]*', '', clean_title)
        clean_title = re.sub(r'^Below are.*?exploits?.*?:', '', clean_title, flags=re.IGNORECASE)
        clean_title = re.sub(r'^Here (?:is|are).*?:', '', clean_title, flags=re.IGNORECASE)

        if len(clean_title) > 80 or ', ' in clean_title[:40]:
            name_match = re.search(r'(?:Name|Title|Exploit):\s*([^,\n]+)', clean_title, re.IGNORECASE)
            if name_match:
                clean_title = name_match.group(1).strip()
            else:
                clean_title = clean_title.split(',')[0].strip()
                if len(clean_title) > 80:
                    clean_title = clean_title[:77] + '...'

        if exploit_content or final_description != original_desc or clean_title != exploit.title:
            exploit.title = clean_title
            exploit.description = final_description or "No description available"
            exploit.exploit_content = exploit_content[:2000] if exploit_content else ""
            updated_count += 1

    await db.commit()

    return {
        "success": True,
        "total_exploits": len(exploits),
        "updated_count": updated_count,
        "message": f"Cleaned up {updated_count} exploits successfully!"
    }
