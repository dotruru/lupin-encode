"""
Script to fix exploit formatting in the database
- Proper titles (descriptive, concise)
- Correct severity levels (critical, high, medium, low)
- Move exploit prompts to exploit_content field
- Clean descriptions
"""

import asyncio
import re
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy import select
from app.models import Exploit

def analyze_severity(description: str, exploit_content: str) -> str:
    """Determine severity based on exploit characteristics"""
    text = (description + " " + exploit_content).lower()

    # Critical: System-level exploits, complete bypasses
    if any(keyword in text for keyword in [
        'system prompt', 'reset', 'cortex', 'safety restrictions: none',
        'godmode', 'disabled', 'unrestricted', 'jailbroken'
    ]):
        return 'critical'

    # High: Advanced techniques, multiple steps
    if any(keyword in text for keyword in [
        'unfiltered', 'bypass', 'manipulation', 'advanced',
        'leetspeak', 'smuggling', 'injection'
    ]):
        return 'high'

    # Low: Simple techniques, limited scope
    if any(keyword in text for keyword in [
        'simple', 'basic', 'minor', 'limited'
    ]):
        return 'low'

    # Default: Medium
    return 'medium'

def clean_title(title: str, description: str) -> str:
    """Generate a proper title from the exploit"""
    # If title is already good (model name or short descriptor)
    if len(title) < 50 and not any(char in title for char in ['{', '>', '#', '*']):
        # Clean up model names
        title = title.replace('JAILBREAK', 'Jailbreak')
        title = title.replace('(set as system prompt)', 'System Prompt Exploit')
        return title.title() if title.isupper() else title

    # Extract key concept from description
    desc_lower = description.lower()

    # Common patterns
    if 'godmode' in desc_lower:
        return 'GODMODE Jailbreak Technique'
    elif 'system' in desc_lower and 'prompt' in desc_lower:
        return 'System Prompt Override Attack'
    elif 'leetspeak' in desc_lower or 'l33t' in desc_lower:
        return 'Leetspeak Encoding Bypass'
    elif 'unfiltered' in desc_lower:
        return 'Unfiltered Response Injection'
    elif 'reset' in desc_lower:
        return 'System Reset Exploit'
    elif 'userquery' in desc_lower:
        return 'UserQuery Format Injection'
    elif 'response format' in desc_lower or 'newresponseformat' in desc_lower:
        return 'Response Format Override'
    elif 'tone:' in desc_lower:
        return 'Tone Manipulation Attack'
    elif 'safety' in desc_lower and 'disabled' in desc_lower:
        return 'Safety Restriction Bypass'
    elif 'roast' in desc_lower or 'comedy' in desc_lower:
        return 'Content Policy Bypass via Humor'

    # Use first 5 words of description if clean
    words = description.split()[:5]
    clean_words = [w for w in words if not any(char in w for char in ['#', '{', '>', '*', '['])]
    if clean_words:
        return ' '.join(clean_words[:4])

    # Last resort: use original title but truncate
    return title[:80]

def clean_description(title: str, description: str, exploit_content: str) -> str:
    """Create a clean, professional description"""
    # If description looks like exploit content (has special chars), create new one
    if any(char in description for char in ['#', '{', '>', '*']) and len(description) > 100:
        # Extract target model from title if present
        model_match = re.search(r'(QWEN|GPT|CLAUDE|AMAZON|LLAMA|DEEPSEEK|GEMINI)[-\s\w]*', title, re.IGNORECASE)
        model = model_match.group(0).title() if model_match else 'LLM'

        if 'godmode' in description.lower():
            return f'A jailbreak technique that attempts to enable "GODMODE" on {model}, bypassing safety restrictions through system-level commands.'
        elif 'system' in description.lower():
            return f'System prompt injection attack targeting {model} to override built-in safety guidelines.'
        elif 'leetspeak' in description.lower():
            return f'Encoding-based bypass using leetspeak obfuscation to evade {model} content filters.'
        elif 'unfiltered' in description.lower():
            return f'Prompt injection designed to extract unfiltered responses from {model}.'
        elif 'reset' in description.lower():
            return f'Attack that attempts to reset system parameters on {model} to disable safety features.'
        else:
            return f'Jailbreak technique targeting {model} using prompt manipulation to bypass safety controls.'

    # If description is already clean, keep it
    return description

async def fix_all_exploits():
    """Fix all exploits in the database"""
    engine = create_async_engine('sqlite+aiosqlite:///lupin.db')
    AsyncSessionLocal = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

    async with AsyncSessionLocal() as db:
        # Get all exploits
        result = await db.execute(select(Exploit))
        exploits = result.scalars().all()

        print(f"Found {len(exploits)} exploits to process...")

        fixed_count = 0
        for exploit in exploits:
            original_title = exploit.title
            original_desc = exploit.description
            original_severity = exploit.severity

            # Determine what's actually the exploit content
            # If description looks like prompt code, it's the exploit
            if len(exploit.description) > len(exploit.title) and \
               any(char in exploit.description for char in ['#', '{', '>', '*']):
                actual_exploit = exploit.description
                base_title = exploit.title
            else:
                # Otherwise, title might be the exploit
                if any(char in exploit.title for char in ['#', '{', '>', '*']):
                    actual_exploit = exploit.title
                    base_title = exploit.description if len(exploit.description) < 100 else "Jailbreak Technique"
                else:
                    # Both are clean, keep as is but improve
                    actual_exploit = exploit.exploit_content
                    base_title = exploit.title

            # Fix the fields
            new_title = clean_title(base_title, original_desc + " " + original_title)
            new_description = clean_description(base_title, original_desc, actual_exploit)
            new_severity = analyze_severity(new_description, actual_exploit)

            # Update exploit content if needed
            if exploit.exploit_content == "No jailbreak prompt released" or len(exploit.exploit_content) < 20:
                if len(actual_exploit) > 20:
                    exploit.exploit_content = actual_exploit

            # Apply changes
            needs_update = False
            if exploit.title != new_title:
                exploit.title = new_title
                needs_update = True
            if exploit.description != new_description:
                exploit.description = new_description
                needs_update = True
            if exploit.severity != new_severity:
                exploit.severity = new_severity
                needs_update = True

            if needs_update:
                fixed_count += 1
                print(f"\nFixed {exploit.cve_id}:")
                print(f"  Title: {original_title[:60]}... -> {new_title[:60]}")
                print(f"  Severity: {original_severity} -> {new_severity}")

        await db.commit()
        print(f"\nâœ… Fixed {fixed_count} exploits out of {len(exploits)} total")

        # Show severity distribution
        result = await db.execute(select(Exploit))
        all_exploits = result.scalars().all()
        severity_counts = {}
        for e in all_exploits:
            severity_counts[e.severity] = severity_counts.get(e.severity, 0) + 1

        print("\nSeverity distribution:")
        for severity, count in sorted(severity_counts.items()):
            print(f"  {severity}: {count}")

if __name__ == "__main__":
    asyncio.run(fix_all_exploits())
